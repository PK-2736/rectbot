name: Backup Supabase to Cloudflare R2

on:
  # æ¯æ—¥åˆå‰3æ™‚ï¼ˆJST = UTC+9 ãªã®ã§ UTC 18:00ï¼‰ã«å®Ÿè¡Œ
  schedule:
    - cron: '0 18 * * *'
  
  # æ‰‹å‹•å®Ÿè¡Œã‚‚å¯èƒ½
  workflow_dispatch:

jobs:
  backup:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install PostgreSQL client
        run: |
          sudo apt-get update
          sudo apt-get install -y postgresql-client

      - name: Install AWS CLI for R2
        run: |
          curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
          unzip awscliv2.zip
          sudo ./aws/install --update

      - name: Configure AWS CLI for Cloudflare R2
        env:
          R2_ACCOUNT_ID: ${{ secrets.R2_ACCOUNT_ID }}
          R2_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
          R2_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}
        run: |
          aws configure set aws_access_key_id $R2_ACCESS_KEY_ID
          aws configure set aws_secret_access_key $R2_SECRET_ACCESS_KEY
          aws configure set region auto

      - name: Create backup directory
        run: mkdir -p backups

      - name: Test Supabase connectivity
        env:
          SUPABASE_PROJECT_REF: ${{ secrets.SUPABASE_PROJECT_REF }}
        run: |
          echo "Testing Supabase database connectivity..."
          
          # DNS è§£æ±ºã‚’ãƒ†ã‚¹ãƒˆ
          echo "DNS Resolution:"
          host db.${SUPABASE_PROJECT_REF}.supabase.co || true
          dig +short AAAA db.${SUPABASE_PROJECT_REF}.supabase.co || true
          
          # IPv6 ãŒåˆ©ç”¨å¯èƒ½ã‹ç¢ºèª
          if [ -f /proc/net/if_inet6 ]; then
            echo "âœ… IPv6 is available on this runner"
            ip -6 addr show | grep "inet6" | grep -v "::1" | head -3
            
            # IPv6 æ¥ç¶šãƒ†ã‚¹ãƒˆï¼ˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆä»˜ãï¼‰
            echo "Testing IPv6 connectivity (timeout 10s)..."
            timeout 10 ping6 -c 2 db.${SUPABASE_PROJECT_REF}.supabase.co || echo "âš ï¸ IPv6 ping failed or filtered"
          else
            echo "âš ï¸ IPv6 is not available"
          fi

      - name: Dump Supabase database
        env:
          SUPABASE_PROJECT_REF: ${{ secrets.SUPABASE_PROJECT_REF }}
          SUPABASE_DB_PASSWORD: ${{ secrets.SUPABASE_DB_PASSWORD }}
        run: |
          TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
          BACKUP_FILE="backups/supabase_backup_${TIMESTAMP}.sql"
          
          echo "Creating database backup: ${BACKUP_FILE}"
          
          # è¤‡æ•°ã®æ¥ç¶šæ–¹æ³•ã‚’è©¦è¡Œ
          SUCCESS=false
          
          # æ–¹æ³•1: IPv4 ã‚’å„ªå…ˆçš„ã«ä½¿ç”¨ï¼ˆ/etc/hosts ã«è¿½åŠ ï¼‰
          echo "Attempting connection method 1: Force IPv4 via /etc/hosts"
          DB_HOST="db.${SUPABASE_PROJECT_REF}.supabase.co"
          
          # DNS ã§ IPv4 ã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’å–å¾—ï¼ˆA ãƒ¬ã‚³ãƒ¼ãƒ‰ï¼‰
          IPV4_ADDR=$(dig +short A ${DB_HOST} | head -n1)
          
          if [ -n "$IPV4_ADDR" ]; then
            echo "Found IPv4 address: ${IPV4_ADDR}"
            echo "${IPV4_ADDR} ${DB_HOST}" | sudo tee -a /etc/hosts
            
            echo "Connecting to: ${DB_HOST} (${IPV4_ADDR}):5432"
            
            if PGPASSWORD="${SUPABASE_DB_PASSWORD}" pg_dump \
              -h "${DB_HOST}" \
              -p 5432 \
              -U postgres \
              -d postgres \
              -v \
              --no-owner \
              --no-acl \
              --clean \
              --if-exists \
              -f "${BACKUP_FILE}" \
              2>&1 | tee dump.log; then
              SUCCESS=true
              echo "âœ… Method 1 succeeded (IPv4 via /etc/hosts)"
            fi
          else
            echo "âš ï¸ No IPv4 address found for ${DB_HOST}"
          fi
          
          # æ–¹æ³•2: Connection Pooler ã‚’ä½¿ç”¨ï¼ˆIPv4 ã‚µãƒãƒ¼ãƒˆï¼‰
          if [ "$SUCCESS" = false ]; then
            echo ""
            echo "Attempting connection method 2: Connection Pooler"
            POOLER_HOST="aws-0-ap-northeast-1.pooler.supabase.com"
            
            echo "Connecting to: ${POOLER_HOST}:5432"
            
            if PGPASSWORD="${SUPABASE_DB_PASSWORD}" pg_dump \
              -h "${POOLER_HOST}" \
              -p 5432 \
              -U "postgres.${SUPABASE_PROJECT_REF}" \
              -d postgres \
              -v \
              --no-owner \
              --no-acl \
              --clean \
              --if-exists \
              -f "${BACKUP_FILE}" \
              2>&1 | tee dump.log; then
              SUCCESS=true
              echo "âœ… Method 2 succeeded (Connection Pooler)"
            fi
          fi
          
          # æ–¹æ³•3: IPv6 çµŒç”±ã§ç›´æ¥æ¥ç¶š
          if [ "$SUCCESS" = false ]; then
            echo ""
            echo "Attempting connection method 3: Direct IPv6 connection"
            
            if PGPASSWORD="${SUPABASE_DB_PASSWORD}" pg_dump \
              -h "db.${SUPABASE_PROJECT_REF}.supabase.co" \
              -p 5432 \
              -U postgres \
              -d postgres \
              -v \
              --no-owner \
              --no-acl \
              --clean \
              --if-exists \
              -f "${BACKUP_FILE}" \
              2>&1 | tee dump.log; then
              SUCCESS=true
              echo "âœ… Method 3 succeeded (Direct IPv6)"
            fi
          fi
          
          # çµæœç¢ºèª
          if [ "$SUCCESS" = true ] && [ -f "${BACKUP_FILE}" ] && [ -s "${BACKUP_FILE}" ]; then
            echo "âœ… Database dump successful"
            ls -lh "${BACKUP_FILE}"
            echo "BACKUP_FILE=${BACKUP_FILE}" >> $GITHUB_ENV
          else
            echo "âŒ All connection methods failed"
            echo "Dump log:"
            cat dump.log
            exit 1
          fi

      - name: Compress backup
        run: |
          echo "Compressing ${BACKUP_FILE}..."
          gzip "${BACKUP_FILE}"
          COMPRESSED_FILE="${BACKUP_FILE}.gz"
          
          # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’è¡¨ç¤º
          ls -lh "${COMPRESSED_FILE}"
          
          echo "COMPRESSED_FILE=${COMPRESSED_FILE}" >> $GITHUB_ENV

      - name: Upload to Cloudflare R2
        env:
          R2_ACCOUNT_ID: ${{ secrets.R2_ACCOUNT_ID }}
          R2_BUCKET_NAME: ${{ secrets.R2_BUCKET_NAME }}
        run: |
          ENDPOINT_URL="https://${R2_ACCOUNT_ID}.r2.cloudflarestorage.com"
          
          echo "Uploading ${COMPRESSED_FILE} to R2..."
          
          aws s3 cp \
            "${COMPRESSED_FILE}" \
            "s3://${R2_BUCKET_NAME}/$(basename ${COMPRESSED_FILE})" \
            --endpoint-url="${ENDPOINT_URL}"
          
          if [ $? -eq 0 ]; then
            echo "âœ… Upload to R2 successful"
          else
            echo "âŒ Upload to R2 failed"
            exit 1
          fi

      - name: Cleanup old backups from R2 (keep last 30 days)
        env:
          R2_ACCOUNT_ID: ${{ secrets.R2_ACCOUNT_ID }}
          R2_BUCKET_NAME: ${{ secrets.R2_BUCKET_NAME }}
        run: |
          ENDPOINT_URL="https://${R2_ACCOUNT_ID}.r2.cloudflarestorage.com"
          CUTOFF_DATE=$(date -d '30 days ago' +%Y%m%d || date -v-30d +%Y%m%d)
          
          echo "Removing backups older than ${CUTOFF_DATE}..."
          
          # R2 ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä¸€è¦§ã‚’å–å¾—
          aws s3 ls "s3://${R2_BUCKET_NAME}/" --endpoint-url="${ENDPOINT_URL}" | \
          while read -r line; do
            # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’æŠ½å‡º
            BACKUP_NAME=$(echo "$line" | awk '{print $4}')
            
            # supabase_backup_ ã§å§‹ã¾ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿å‡¦ç†
            if [[ "$BACKUP_NAME" =~ ^supabase_backup_([0-9]{8})_ ]]; then
              BACKUP_DATE="${BASH_REMATCH[1]}"
              
              # æ—¥ä»˜æ¯”è¼ƒ
              if [ "$BACKUP_DATE" -lt "$CUTOFF_DATE" ]; then
                echo "Deleting old backup: ${BACKUP_NAME}"
                aws s3 rm "s3://${R2_BUCKET_NAME}/${BACKUP_NAME}" --endpoint-url="${ENDPOINT_URL}"
              fi
            fi
          done
          
          echo "âœ… Cleanup completed"

      - name: Backup summary
        if: always()
        run: |
          echo "## ğŸ“Š Backup Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Timestamp:** $(date)" >> $GITHUB_STEP_SUMMARY
          echo "- **Backup File:** ${COMPRESSED_FILE:-N/A}" >> $GITHUB_STEP_SUMMARY
          
          if [ -f "${COMPRESSED_FILE}" ]; then
            FILE_SIZE=$(ls -lh "${COMPRESSED_FILE}" | awk '{print $5}')
            echo "- **File Size:** ${FILE_SIZE}" >> $GITHUB_STEP_SUMMARY
            echo "- **Status:** âœ… Success" >> $GITHUB_STEP_SUMMARY
          else
            echo "- **Status:** âŒ Failed" >> $GITHUB_STEP_SUMMARY
          fi

      - name: Notify on failure
        if: failure()
        run: |
          echo "âš ï¸ Backup failed! Check the logs for details."
          # ã“ã“ã« Discord ã‚„ Slack ã¸ã®é€šçŸ¥ã‚’è¿½åŠ å¯èƒ½
